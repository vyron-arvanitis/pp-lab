\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ai-lab-repo}
\citation{ai-lab-repo}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Smart simulation strategy: a neural network filters generated events before expensive detector simulation. Figure adapted from the official LMU AI Lab repository\nobreakspace  {}\cite  {ai-lab-repo}.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:smart_sim}{{1}{2}{Smart simulation strategy: a neural network filters generated events before expensive detector simulation. Figure adapted from the official LMU AI Lab repository~\cite {ai-lab-repo}}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}The Belle experiment}{2}{section.2}\protected@file@percent }
\citation{belle2-image}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Closeup of the Belle\nobreakspace  {}II detector indicating all the different subdetectors\nobreakspace  {}\cite  {belle2-image}.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:belle-detector-overview}{{2}{3}{Closeup of the Belle~II detector indicating all the different subdetectors~\cite {belle2-image}}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Belle\nobreakspace  {}II subdetectors and the particles they primarily detect.}}{3}{table.1}\protected@file@percent }
\newlabel{table:belle-subdetectors}{{1}{3}{Belle~II subdetectors and the particles they primarily detect}{table.1}{}}
\citation{belle2-Y-resonances}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Problem Description}{4}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Cross section of $e^+e^-$ with respect to the center-of-mass energy [GeV] \cite  {belle2-Y-resonances}.}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:upsilon-resonances}{{3}{4}{Cross section of $e^+e^-$ with respect to the center-of-mass energy [GeV] \cite {belle2-Y-resonances}}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Theory}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Deep Sets}{5}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Schematic illustration of a Deep Set model.}}{5}{figure.4}\protected@file@percent }
\newlabel{fig:deepset}{{4}{5}{Schematic illustration of a Deep Set model}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Graph Neural Networks}{6}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Analogy between CNNs and GCNs. In CNNs, pixels are updated based on spatial neighborhoods; in GCNs, nodes are updated based on graph neighborhoods.}}{6}{figure.5}\protected@file@percent }
\newlabel{fig:gcn}{{5}{6}{Analogy between CNNs and GCNs. In CNNs, pixels are updated based on spatial neighborhoods; in GCNs, nodes are updated based on graph neighborhoods}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Transformer}{6}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The Dataset}{7}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Transforming the feature values}{7}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Unecessary Features}{8}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{8}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{8}{section.6}\protected@file@percent }
\bibstyle{plain}
\bibdata{mybib}
\bibcite{belle2-image}{1}
\bibcite{belle2-Y-resonances}{2}
\bibcite{ai-lab-repo}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Validation accuracy and loss for different experiments. The horizontal dashed lines indicate the best performance achieved with the baseline model. Note: the \textbf  {reversed} model refers to the configuration where the GCN and DeepSet layers were swapped.}}{10}{figure.6}\protected@file@percent }
\newlabel{fig:Feature_importance}{{6}{10}{Validation accuracy and loss for different experiments. The horizontal dashed lines indicate the best performance achieved with the baseline model. Note: the \textbf {reversed} model refers to the configuration where the GCN and DeepSet layers were swapped}{figure.6}{}}
\gdef \@abspage@last{11}
