\section{Results}

\subsection{Optimal model}

Section~\ref{sec:methodology} discusses strategies for regularization, feature processing, and hyperparameter optimization, while Section~\ref{sec:models} investigates architectural modifications to identify the most effective model design.
Based on the insights gained, we combined the most effective components into a single architecture, referred to as the Optimal Model. 

The model builds upon a base architecture in which the input features are augmented with PDG ID embeddings, increasing the feature dimensionality by 25. The network consists of four sequential layers: the input layer, second, and third layer are implemented as GCNs, followed by one linear layer. This is followed by mean pooling across particles and a final two-layer MLP to produce the output. 

Each trainable layer is followed by dropout (with a rate of $0.179$), a LeakyReLU activation (slope $0.01$), and Batch Normalization. Training was conducted using cylindrical coordinates, while all other settings remained consistent with previous experiments. 

Table \ref{tab:optimalmodel_arc} presents the architecture of the optimal model. Achieving a training loss of $0.451$ with a training accuracy of $79.0\%$, and a
validation loss of $0.430$ with an accuracy of $80.1\%$, it was identified as the best-performing model.

\begin{table}[H]
    \caption{Architecture of the Optimal Model}
    \label{tab:optimalmodel_arc}
    \centering
    \begin{tabular}{l|l|c|c}
        \hline
        Layer \# & Description & Output shape & Parameters \\
        \hline 
        1 & Embedding lookup (PDG code) & $[B,N,e]$ & $(n_\text{PDG} + 1) \times e $ \\
        -- & Concatenation of features and embeddings & $[B,N,f+e]$ & -- \\
        2 & GCN layer + BatchNorm, LeakyReLU, Dropout & $[B,N,u]$ & $u \times (f+e) + u$ \\
        3-4 & GCN layer + BatchNorm, LeakyReLU, Dropout & $[B,N,u]$ & $u \times u + u$ \\
        5 & Linear layer + BatchNorm, LeakyReLU, Dropout& $[B,N,u]$ & $u \times u + u$ \\
        --& Masked mean pooling (or mean over $N$)& $[B,u]$& -- \\
        6& Linear + BatchNorm, LeakyReLU, Dropout & $[B,u]$ & $u \times u + u$ \\ 
        7& Linear (output layer) & $[B,1]$ & $1 \times u + 1$ \\
        \hline
    \end{tabular}
\end{table}


\subsection{ROC curves and speedup results}

Figures~\ref{fig:ROC_curves_results} and~\ref{fig:speedup} present the ROC curves and speedup plots for our most promising models.  
We began with a simple Deep Set model (\ref{sec:DeepSet}) and, 
through a series of investigations, developed more complex architectures such as the Deep Set Combined model and the Deep Set Combined with GCN model.  
Our exploration culminated in a Transformer model and an ``Optimal Model'' configuration.


\begin{figure}[H]
 \centering
    \includegraphics[width=0.75\textwidth]{chapters/Results/ROC_curves.pdf}
    \caption{The resulting ROC curves of our different models}
    \label{fig:ROC_curves_results}
\end{figure}

From figure~\ref{fig:ROC_curves_results}, it is evident that all but 
the simplest baseline models achieve strong results,  
with most AUC scores exceeding $0.85$, indicating strong classification performance.  
The Transformer and Optimal Model stand out with the highest AUC values.

While ROC curves indicate classification quality, they do not reflect entirely the impact
on computational efficiency. To address this, we also evaluate the speedup, as discussed in section (\ref{sec:Speedup}),
if events are filtered using the model predictions.

\begin{figure}[H]
 \centering
    \includegraphics[width=0.75\textwidth]{chapters/Results/Speedup.png}
    \caption{Speedup gained by our separate models}
    \label{fig:speedup}
\end{figure}

From figure \ref{fig:ROC_curves_results}, we observe that the more advanced models are nearly indistinguishable in terms of ROC performance; however, they diverge significantly in the achievable speedup, as shown in figure \ref{fig:speedup}.
The Optimal Model attains the highest maximum speedup, 
followed closely by the Transformer and Deep Set Combined with GCN variants.


\begin{table}[h]
    \centering
    \caption{Evaluation metrics on the test dataset for all models}
    \label{tab:model_summary}
    \begin{tabular}{l|c|c|c|c|c}
        \hline
        \textbf{Model} & \textbf{Loss} & \textbf{Acc. (\%)} & \textbf{AUC} & \textbf{Max. Speedup} & \textbf{Best Threshold} \\
        \hline
        DS & $0.633$ & $63.6$ & $0.699$ & $2.485$ & $0.618$ \\
        DS\_combined & $0.476$ & $77.5$ & $0.852$ & $4.758$ & $1.757$ \\
        DS\_gcn & $0.614$ & $66.0$ & $0.721$ & $2.795$ & $1.149$ \\
        DS\_combined\_wgcn & $0.464$ & $78.0$ & $0.862$ & $5.323$ & $1.586$ \\
        transformer & $0.441$ & $79.5$ & $0.872$ & $5.301$ & $1.774$ \\
        DS\_combined\_wgcn\_norm & $0.467$ & $77.6$ & $0.860$ & $5.373$ & $1.719$ \\
        optimal\_model & $0.432$ & $80.1$ & $0.880$ & $6.009$ & $1.899$ \\
        \hline
    \end{tabular}
\end{table}

The "Best Threshold" column is obtained from the set 
of decision thresholds returned by the \verb|roc_curve| function.  
These thresholds correspond to decreasing cut values on 
the modelâ€™s decision function that are used to compute 
the true positive rate (TPR) and false positive rate (FPR) pairs.  
The first threshold is always set to \verb|np.inf|, 
which by definition yields zero predicted positives.  

Among these thresholds, the one shown in the table is 
the value at which the model 
achieves its maximum estimated speedup.  
For example, the Optimal Model reaches a 
maximum speedup of $5.934$ at a decision threshold of $1.901$.
