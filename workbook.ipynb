{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6227b49-845f-4081-9d55-6d0264b825f7",
   "metadata": {},
   "source": [
    "# Workbook\n",
    "\n",
    "This notebook contains all the necessary code (reading data, preprocessing, padding, masking, etc.) from [dataset_and_models.ipynb](dataset_and_models.ipynb) to get started on building and training the neural networks for the excercises in [labday.md](labday.md). The utility functions are now imported from python modules. It is advised to also put your model definitions in a module once finalized.\n",
    "\n",
    "As mentioned there, make sure to:\n",
    "* define your Model(s) with configurable hyperparameters as functions or classes.\n",
    "* be able to save/load your model and all states necessary to evaluate this later on an independent test data set.\n",
    "\n",
    "It also makes sense to copy this notebook (or copy the code into script/modules) for building different models (e.g. the Deep Set NN from task 2 and the GCN from task 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05038a43-c9f2-4ba2-b72d-56fe7ce2c7c1",
   "metadata": {},
   "source": [
    "# Reading, Converting and Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a27e99-9332-4da5-a610-d86798f61369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload changed modules (see https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html for caveats)\n",
    "%load_ext autoreload\n",
    "%autoreload all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ec5a56-fb16-47d0-9e20-4c2c3b91072f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import (\n",
    "    load_data,\n",
    "    get_adj,\n",
    "    preprocess,\n",
    "    GraphDataset,\n",
    "    collate_fn,\n",
    "    fit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a4e08e-26e4-41cb-a055-01212f7fd7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_columns = [\"prodTime\", \"x\", \"y\", \"z\", \"energy\", \"px\", \"py\", \"pz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c10f5d-3298-4f54-b27a-cca1684c60ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, labels = load_data(\"smartbkg_dataset_4k.parquet\", row_groups=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e807ac-9856-403d-aaab-de9db212dc93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"pdg_mapping.json\") as f:\n",
    "    pdg_mapping = dict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731249b9-3f22-4028-b25f-530175684352",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess(df, pdg_mapping=pdg_mapping, feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f1b96-7c0a-4873-ab99-8e3c1675855a",
   "metadata": {},
   "source": [
    "# Adjacency Matrix and GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b516687-f0ff-48f0-a229-7c721521e65c",
   "metadata": {},
   "source": [
    "For GCN models we also need the adjacency matrices (for others it can be ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213df721-ca6b-4b9e-bf46-91ca69c883f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"adj\"] = [get_adj(index, mother) for index, mother in zip(data[\"index\"], data[\"mother\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b45990-b1ba-4baa-854b-4098e6ef9b0c",
   "metadata": {},
   "source": [
    "# Build a model\n",
    "Example models from the introductory notebook are provided in `models.py`. Adjust them to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d01cf52-3a60-43bd-a281-ede9522eed4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import from_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe8f67-4c33-4fef-9256-113790867a75",
   "metadata": {},
   "source": [
    "It's good practice to make your model setups reproducible from a single configuration which you can store to reproduce your model later, e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6091e64-f017-49e1-b068-35b264e8c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(\"saved_models\")\n",
    "save_path.mkdir(exist_ok=True)\n",
    "tag = \"deepset_combined_wgcn\" # name identifying the setup (used to name the folder to save model and configuration to)\n",
    "model_path = save_path / tag\n",
    "model_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c7f302a-4daa-41e4-baae-ff408415e39f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"deepset_combined_wgcn\",\n",
    "    \"units\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f4f58b-5f3c-46ce-a774-9713bbb967ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(model_path / f\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3ed2011-fb2a-425c-a879-0394cd683735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = from_config(config) # build model from config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "965f9300-c384-4538-8beb-bbf30bca5a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedModel_wGCN(\n",
       "  (embedding_layer): Embedding(185, 8)\n",
       "  (gcn_layer): GCN(\n",
       "    (linear): Linear(in_features=16, out_features=32, bias=True)\n",
       "  )\n",
       "  (deep_set_layer): DeepSetLayer(\n",
       "    (per_item_mlp): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (global_mlp): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): OutputLayer(\n",
       "    (output_layer): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084835da-ed00-4fa6-b770-16a8d05fd9bf",
   "metadata": {},
   "source": [
    "# Fit Model\n",
    "This section features the generator for the gcn models that provides `features`, `pdg_mapped` and `adj` - you can also use it for models that don't use all inputs, if you define the `forward` function to take a batch as a dictionary, ignoring the unused keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e346eca5-5e4d-4078-913c-e8ad15409924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = {}\n",
    "data_val = {}\n",
    "(\n",
    "    data_train[\"features\"], data_val[\"features\"],\n",
    "    data_train[\"pdg_mapped\"], data_val[\"pdg_mapped\"],\n",
    "    data_train[\"adj\"], data_val[\"adj\"],\n",
    "    y_train, y_val\n",
    ") = train_test_split(data[\"features\"], data[\"pdg_mapped\"], data[\"adj\"], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23c0c044-747c-46d5-ad3d-5747d6c61a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_val = [\n",
    "    torch.utils.data.DataLoader(\n",
    "        GraphDataset(feat=x[\"features\"], pdg=x[\"pdg_mapped\"], adj=x[\"adj\"], y=y),\n",
    "        batch_size=256,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    for x, y in [(data_train, y_train), (data_val, y_val)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b1f62b-6d3b-4e1b-9f4d-7d2ad6059a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de75927-321b-4c88-86e1-6dbb1fdecf76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Batch 292/293, Train loss: 0.649, Train accuracy: 0.614, Validation loss: 0.597, Validation accuracy: 0.677\n",
      "Epoch 1\n",
      "Batch 292/293, Train loss: 0.576, Train accuracy: 0.698, Validation loss: 0.549, Validation accuracy: 0.719\n",
      "Epoch 2\n",
      "Batch 292/293, Train loss: 0.547, Train accuracy: 0.723, Validation loss: 0.531, Validation accuracy: 0.734\n",
      "Epoch 3\n",
      "Batch 292/293, Train loss: 0.532, Train accuracy: 0.736, Validation loss: 0.518, Validation accuracy: 0.744\n",
      "Epoch 4\n",
      "Batch 292/293, Train loss: 0.521, Train accuracy: 0.744, Validation loss: 0.508, Validation accuracy: 0.752\n",
      "Epoch 5\n",
      "Batch 292/293, Train loss: 0.514, Train accuracy: 0.749, Validation loss: 0.502, Validation accuracy: 0.755\n",
      "Epoch 6\n",
      "Batch 292/293, Train loss: 0.508, Train accuracy: 0.753, Validation loss: 0.496, Validation accuracy: 0.759\n",
      "Epoch 7\n",
      "Batch 255/293, Train loss: 0.504, Train accuracy: 0.756\r"
     ]
    }
   ],
   "source": [
    "history = fit(model, dl_train, dl_val, epochs=10, history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b30cb-2f6e-4557-9b05-e7c651e88c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4359c02-2d63-4e23-8bf9-e2a165b2ffcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "df_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c184d9-a9b9-4731-9f56-cc86ed15a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history.to_csv(model_path / \"history.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7cf2a3-cd8d-4b9d-9040-e4f4a6cbe429",
   "metadata": {},
   "source": [
    "After training you should then save your model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e26897-bf07-4eae-ba4b-5889a243d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path / \"state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d085c88-609e-4495-a2a4-a1320b3f2f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pp)",
   "language": "python",
   "name": "pp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
